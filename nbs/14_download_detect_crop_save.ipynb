{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download-Unzip & Detecting & Cropping Faces & Saving\n",
    "\n",
    "> - Download and Unzip Part File\n",
    "> - Detection is made on only original video for time saving\n",
    "> - While cropping fake images original face detections are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp face_detection.download_detect_crop_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai.vision import *\n",
    "\n",
    "from dfdc.core.core import *\n",
    "from dfdc.core.download_unzip import *\n",
    "from dfdc.face_detection.generate_detections import *\n",
    "from dfdc.face_detection.save_cropped_faces import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
       "       '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49'], dtype='<U2')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(download_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_part_no = \"00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = download_unzip(download_part_no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_no = video_path.name.split(\"_\")[-1]; part_no"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Faces from Original Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"mobilenet\"\n",
    "data_path = Path(\"/home/ubuntu/data/dfdc/\")\n",
    "video_path = Path(data_path/f\"dfdc_train/dfdc_train_part_{part_no}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1335"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(video_path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf = read_metadata(get_files(video_path, extensions=['.json'], recurse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files_txt = video_path/\"original_video_files.txt\"\n",
    "_ = get_original_video_list(video_path, metadf, video_files_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_fname = data_path/f\"dfdc_face_detections/part_{part_no}_retina_detections.csv\"\n",
    "freq = 10\n",
    "model_args = dict(confidence_threshold = 0.5, top_k = 5, nms_threshold = 0.5, keep_top_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/86 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/ubuntu/git/dfdc/local_misc/pytorch_retinaface/weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 86/86 [01:38<00:00,  1.15s/it]\n"
     ]
    }
   ],
   "source": [
    "df = generate_face_detections(video_files_txt, freq, \"mobilenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fgobmbcami.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[567, 188, 747...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yxvmusxvcz.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[646, 604, 721...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prmwoaeeng.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[759, 158, 974...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yexeazbqig.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1461, 224, 16...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qyqufaskjs.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[435, 315, 538...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           source          size  \\\n",
       "0  fgobmbcami.mp4  (1080, 1920)   \n",
       "1  yxvmusxvcz.mp4  (1920, 1080)   \n",
       "2  prmwoaeeng.mp4  (1080, 1920)   \n",
       "3  yexeazbqig.mp4  (1080, 1920)   \n",
       "4  qyqufaskjs.mp4  (1920, 1080)   \n",
       "\n",
       "                                     face_detections  n_frames  sample_freq  \\\n",
       "0  [{'frame_no': 0, 'detections': [[567, 188, 747...        30           10   \n",
       "1  [{'frame_no': 0, 'detections': [[646, 604, 721...        30           10   \n",
       "2  [{'frame_no': 0, 'detections': [[759, 158, 974...        30           10   \n",
       "3  [{'frame_no': 0, 'detections': [[1461, 224, 16...        30           10   \n",
       "4  [{'frame_no': 0, 'detections': [[435, 315, 538...        30           10   \n",
       "\n",
       "   len_video  \n",
       "0        300  \n",
       "1        300  \n",
       "2        300  \n",
       "3        300  \n",
       "4        300  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop and Save Faces for All Videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf[\"source\"] = metadf.apply(lambda o: o['original'] \n",
    "                                if type(o['original']) == str else o['fname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"fname\":\"source\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections_df = metadf.merge(df, how='inner', on='source')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>owxbbpjpch.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[427, 311, 527...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bpguesjrfa.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[427, 311, 527...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skewcclbhg.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[427, 311, 527...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ybdtkypwez.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[427, 311, 527...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qwvxbksoeo.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>wynotylpnm.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[427, 311, 527...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname label  split        original          source          size  \\\n",
       "0  owxbbpjpch.mp4  FAKE  train  wynotylpnm.mp4  wynotylpnm.mp4  (1920, 1080)   \n",
       "1  bpguesjrfa.mp4  FAKE  train  wynotylpnm.mp4  wynotylpnm.mp4  (1920, 1080)   \n",
       "2  skewcclbhg.mp4  FAKE  train  wynotylpnm.mp4  wynotylpnm.mp4  (1920, 1080)   \n",
       "3  ybdtkypwez.mp4  FAKE  train  wynotylpnm.mp4  wynotylpnm.mp4  (1920, 1080)   \n",
       "4  qwvxbksoeo.mp4  FAKE  train  wynotylpnm.mp4  wynotylpnm.mp4  (1920, 1080)   \n",
       "\n",
       "                                     face_detections  n_frames  sample_freq  \\\n",
       "0  [{'frame_no': 0, 'detections': [[427, 311, 527...        30           10   \n",
       "1  [{'frame_no': 0, 'detections': [[427, 311, 527...        30           10   \n",
       "2  [{'frame_no': 0, 'detections': [[427, 311, 527...        30           10   \n",
       "3  [{'frame_no': 0, 'detections': [[427, 311, 527...        30           10   \n",
       "4  [{'frame_no': 0, 'detections': [[427, 311, 527...        30           10   \n",
       "\n",
       "   len_video  \n",
       "0        300  \n",
       "1        300  \n",
       "2        300  \n",
       "3        300  \n",
       "4        300  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections_csv = data_path/f'dfdc_face_detections/part_{part_no}_retina_detections.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections_df.to_csv(face_detections_csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1334"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(face_detections_df.fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_cropped_faces(data_path, video_path, face_detections_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12', '13', '14', '15', '16', '17',\n",
       "       '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35',\n",
       "       '36', '37', '38', '39', '40', '41', '42', '43', '44', '45', '46', '47', '48', '49'], dtype='<U2')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array(download_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def download_detect_crop_save(download_part_no):\n",
    "    # Download and Unzip\n",
    "    print(f\"Downloading part {download_part_no}\")\n",
    "    video_path = download_unzip(download_part_no)\n",
    "    part_no = video_path.name.split(\"_\")[-1]\n",
    "\n",
    "    # Detect Faces from Original Videos\n",
    "    modelname = \"mobilenet\"\n",
    "    data_path = Path(\"/home/ubuntu/data/dfdc/\")\n",
    "    video_path = Path(data_path/f\"dfdc_train/dfdc_train_part_{part_no}/\")\n",
    "    metadf = read_metadata(get_files(video_path, extensions=['.json'], recurse=True)[0])\n",
    "    video_files_txt = video_path/\"original_video_files.txt\"\n",
    "    _ = get_original_video_list(video_path, metadf, video_files_txt)\n",
    "\n",
    "    dest_fname = data_path/f\"dfdc_face_detections/part_{part_no}_retina_detections.csv\"\n",
    "    freq = 10\n",
    "    model_args = dict(confidence_threshold = 0.5, top_k = 5, nms_threshold = 0.5, keep_top_k = 5)\n",
    "    df = generate_face_detections(video_files_txt, freq, \"mobilenet\")\n",
    "\n",
    "    # Crop and Save Faces for All Videos \n",
    "    metadf[\"source\"] = metadf.apply(lambda o: o['original'] if type(o['original']) == str else o['fname'], axis=1)\n",
    "    df = df.rename(columns={\"fname\":\"source\"})\n",
    "    face_detections_df = metadf.merge(df, how='inner', on='source')\n",
    "    \n",
    "    # Keep only existing videos (video dir missing videos which is in metadata)\n",
    "    video_files = get_files(video_path, extensions=['.mp4'], recurse=True)\n",
    "    video_file_fnames = [o.name for o in video_files]\n",
    "    face_detections_df = face_detections_df[face_detections_df.fname.isin(video_file_fnames)].reset_index(drop=True)\n",
    "    \n",
    "    # Do crop and save\n",
    "    face_detections_csv = data_path/f'dfdc_face_detections/part_{part_no}_retina_detections.csv'\n",
    "    face_detections_df.to_csv(face_detections_csv, index=False)\n",
    "    save_cropped_faces(data_path, video_path, face_detections_csv)\n",
    "\n",
    "    # Remove videos\n",
    "    shutil.rmtree(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_path = Path(f'/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_{part_no}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(crop_path.ls())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_crop_dir(crop_dir):\n",
    "    il = ImageList.from_folder(crop_dir)\n",
    "    n = int(np.ceil(np.sqrt(len(il.items)))); n\n",
    "    axes = subplots(n,n).flatten()\n",
    "    for img, ax in zip(il, axes): img.show(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_src = np.random.choice(list(set(metadf.source)))\n",
    "orig_fname = metadf[metadf.fname == rand_src].fname.values[0]\n",
    "fnames = metadf[metadf.source == rand_src].fname.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_dir = (crop_path/Path(orig_fname).stem); print(crop_dir)\n",
    "show_crop_dir(crop_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_fname = Path(np.random.choice(fnames))\n",
    "crop_dir = (crop_path/rand_fname.stem); print(crop_dir)\n",
    "show_crop_dir(crop_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfdc.core.video_core import *\n",
    "play_video(video_path/f'{orig_fname}', video_path/f'{rand_fname}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 001 - extract_faces.ipynb.\n",
      "Converted 002 - face_detection_retinaface.ipynb.\n",
      "Converted 003 - save_face_crops.ipynb.\n",
      "Converted 004 - tl_baseline.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 01_video_core.ipynb.\n",
      "Converted 02_download_unzip_files.ipynb.\n",
      "Converted 10_bbox_utils.ipynb.\n",
      "Converted 11_retinaface_detection.ipynb.\n",
      "Converted 12_generate_face_detections.ipynb.\n",
      "Converted 13_save_cropped_faces.ipynb.\n",
      "Converted 14_download_detect_crop_save.ipynb.\n",
      "Converted 15_extract_all.ipynb.\n",
      "Converted 20_datasets.ipynb.\n",
      "Converted 21_single_frame_model.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted inspect original fake pairs for face detection.ipynb.\n",
      "Converted run_commands.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepfake]",
   "language": "python",
   "name": "conda-env-deepfake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
