{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfdc.core.core import *\n",
    "from dfdc.core.video_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/ubuntu/data/dfdc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_path = data_path/'dfdc_face_detections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_face_detections/part_38_retina_detections.csv'))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections_path.ls()), detections_path.ls()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "croppped_path = data_path/'dfdc_cropped_faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_37'))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(croppped_path.ls()), croppped_path.ls()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read detections df and crop files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfdc.core.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_no = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_df = read_face_detection_df(detections_path/f'part_{part_no}_retina_detections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oyixebfpcl.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shclgsfxtj.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mutuhmwjdv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rohakxryar.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fpiybwcszz.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname label  split        original          source          size  \\\n",
       "0  oyixebfpcl.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "1  shclgsfxtj.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "2  mutuhmwjdv.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "3  rohakxryar.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "4  fpiybwcszz.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "\n",
       "                                     face_detections  n_frames  sample_freq  \\\n",
       "0  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "1  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "2  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "3  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "4  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "\n",
       "   len_video  \n",
       "0        299  \n",
       "1        299  \n",
       "2        299  \n",
       "3        299  \n",
       "4        299  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'frame_no': 0,\n",
       "  'detections': [[1300, 351, 1555, 588]],\n",
       "  'landmarks': [[1333, 441, 1439, 444, 1349, 477, 1327, 525, 1407, 527]]},\n",
       " {'frame_no': 10,\n",
       "  'detections': [[1306, 351, 1555, 580]],\n",
       "  'landmarks': [[1338, 439, 1437, 441, 1349, 473, 1333, 521, 1408, 522]]},\n",
       " {'frame_no': 20,\n",
       "  'detections': [[1312, 349, 1551, 566]],\n",
       "  'landmarks': [[1336, 436, 1429, 438, 1343, 472, 1333, 515, 1404, 516]]},\n",
       " {'frame_no': 30,\n",
       "  'detections': [[1312, 337, 1561, 558]],\n",
       "  'landmarks': [[1338, 422, 1436, 425, 1345, 456, 1334, 504, 1410, 505]]},\n",
       " {'frame_no': 40,\n",
       "  'detections': [[1326, 317, 1567, 542], [373, 360, 698, 696]],\n",
       "  'landmarks': [[1354, 397, 1452, 405, 1355, 431, 1337, 479, 1414, 485],\n",
       "   [557, 490, 651, 490, 663, 549, 577, 614, 650, 615]]},\n",
       " {'frame_no': 50,\n",
       "  'detections': [[393, 358, 685, 674], [1327, 301, 1575, 526]],\n",
       "  'landmarks': [[580, 483, 625, 476, 688, 530, 603, 596, 643, 592],\n",
       "   [1367, 383, 1470, 384, 1382, 408, 1351, 462, 1435, 463]]},\n",
       " {'frame_no': 60,\n",
       "  'detections': [[1345, 307, 1587, 519]],\n",
       "  'landmarks': [[1380, 383, 1477, 388, 1391, 411, 1371, 461, 1447, 465]]},\n",
       " {'frame_no': 70,\n",
       "  'detections': [[391, 360, 700, 679], [1356, 305, 1598, 515]],\n",
       "  'landmarks': [[591, 492, 643, 485, 696, 541, 599, 601, 644, 597],\n",
       "   [1390, 384, 1481, 387, 1396, 412, 1382, 461, 1455, 464]]},\n",
       " {'frame_no': 80,\n",
       "  'detections': [[380, 352, 687, 679], [1341, 310, 1582, 525]],\n",
       "  'landmarks': [[566, 484, 630, 477, 679, 533, 591, 598, 643, 594],\n",
       "   [1371, 391, 1468, 393, 1383, 420, 1367, 469, 1442, 471]]},\n",
       " {'frame_no': 90,\n",
       "  'detections': [[372, 343, 673, 659], [1333, 313, 1573, 535]],\n",
       "  'landmarks': [[552, 475, 613, 463, 658, 525, 577, 587, 625, 579],\n",
       "   [1364, 395, 1462, 397, 1372, 424, 1356, 474, 1434, 475]]},\n",
       " {'frame_no': 100,\n",
       "  'detections': [[367, 346, 663, 661], [1333, 316, 1574, 541]],\n",
       "  'landmarks': [[539, 469, 616, 462, 642, 523, 559, 583, 618, 578],\n",
       "   [1360, 399, 1451, 400, 1362, 431, 1353, 482, 1423, 483]]},\n",
       " {'frame_no': 110,\n",
       "  'detections': [[1328, 325, 1565, 543], [388, 327, 680, 686]],\n",
       "  'landmarks': [[1351, 403, 1442, 402, 1354, 432, 1346, 485, 1418, 484],\n",
       "   [572, 457, 635, 462, 668, 522, 584, 591, 636, 596]]},\n",
       " {'frame_no': 120,\n",
       "  'detections': [[1313, 324, 1550, 540]],\n",
       "  'landmarks': [[1340, 402, 1430, 401, 1345, 432, 1338, 482, 1409, 480]]},\n",
       " {'frame_no': 130,\n",
       "  'detections': [[1302, 324, 1542, 545]],\n",
       "  'landmarks': [[1328, 406, 1423, 403, 1339, 436, 1331, 489, 1403, 486]]},\n",
       " {'frame_no': 140,\n",
       "  'detections': [[1301, 327, 1537, 544]],\n",
       "  'landmarks': [[1329, 409, 1421, 405, 1340, 439, 1331, 490, 1402, 487]]},\n",
       " {'frame_no': 150,\n",
       "  'detections': [[1299, 326, 1534, 545]],\n",
       "  'landmarks': [[1326, 408, 1421, 405, 1340, 439, 1328, 490, 1402, 488]]},\n",
       " {'frame_no': 160,\n",
       "  'detections': [[1297, 326, 1532, 541]],\n",
       "  'landmarks': [[1324, 408, 1422, 407, 1337, 438, 1325, 489, 1400, 488]]},\n",
       " {'frame_no': 170,\n",
       "  'detections': [[1294, 325, 1531, 549]],\n",
       "  'landmarks': [[1324, 406, 1418, 404, 1335, 438, 1321, 491, 1395, 489]]},\n",
       " {'frame_no': 180,\n",
       "  'detections': [[1288, 328, 1524, 541]],\n",
       "  'landmarks': [[1318, 408, 1411, 407, 1327, 434, 1315, 486, 1390, 485]]},\n",
       " {'frame_no': 190,\n",
       "  'detections': [[1288, 327, 1524, 543]],\n",
       "  'landmarks': [[1316, 408, 1408, 407, 1323, 435, 1313, 487, 1386, 487]]},\n",
       " {'frame_no': 200,\n",
       "  'detections': [[1290, 330, 1520, 546]],\n",
       "  'landmarks': [[1315, 409, 1403, 410, 1316, 439, 1309, 489, 1378, 490]]},\n",
       " {'frame_no': 210,\n",
       "  'detections': [[1287, 331, 1519, 543]],\n",
       "  'landmarks': [[1313, 408, 1401, 409, 1314, 437, 1307, 487, 1377, 487]]},\n",
       " {'frame_no': 220,\n",
       "  'detections': [[368, 339, 667, 680]],\n",
       "  'landmarks': [[551, 474, 619, 473, 660, 529, 567, 593, 624, 594]]},\n",
       " {'frame_no': 230,\n",
       "  'detections': [[1286, 327, 1516, 542], [360, 352, 676, 692]],\n",
       "  'landmarks': [[1314, 409, 1397, 409, 1314, 437, 1309, 487, 1374, 487],\n",
       "   [544, 477, 626, 481, 653, 531, 570, 602, 630, 606]]},\n",
       " {'frame_no': 240,\n",
       "  'detections': [[1287, 326, 1513, 541]],\n",
       "  'landmarks': [[1310, 404, 1399, 406, 1316, 438, 1306, 486, 1375, 487]]},\n",
       " {'frame_no': 250,\n",
       "  'detections': [[1282, 330, 1512, 541]],\n",
       "  'landmarks': [[1310, 409, 1398, 411, 1313, 437, 1303, 485, 1373, 487]]},\n",
       " {'frame_no': 260,\n",
       "  'detections': [[1279, 327, 1512, 540]],\n",
       "  'landmarks': [[1306, 407, 1394, 408, 1307, 434, 1300, 484, 1370, 485]]},\n",
       " {'frame_no': 270,\n",
       "  'detections': [[1282, 326, 1509, 538]],\n",
       "  'landmarks': [[1306, 402, 1398, 405, 1312, 433, 1298, 482, 1369, 484]]},\n",
       " {'frame_no': 280,\n",
       "  'detections': [[1282, 327, 1509, 537]],\n",
       "  'landmarks': [[1303, 401, 1397, 404, 1311, 433, 1297, 481, 1369, 483]]},\n",
       " {'frame_no': 290,\n",
       "  'detections': [[1275, 327, 1507, 536]],\n",
       "  'landmarks': [[1300, 404, 1391, 406, 1306, 435, 1294, 481, 1366, 483]]}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_df['face_detections'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701, 10)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dets in detections_df['face_detections']: \n",
    "    if [o['detections'] for o in dets] == []: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_part_path = croppped_path/f'dfdc_train_part_{part_no}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_dirs = [o for o in cropped_part_path.ls() if (o.ls()) == []] # no detections - false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_files = get_files(cropped_part_path, extensions=['.jpg'], recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40087"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_22_30.jpg'),\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_14_30.jpg'),\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_10_30.jpg'),\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_20_30.jpg')]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped_files[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Collect and sort frames for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoframes_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in cropped_files: videoframes_dict[o.parent.name].append(\"/\".join(str(o).split(\"/\")[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1544"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videoframes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in videoframes_dict.items(): \n",
    "    new_v = sorted(v, key=lambda o: int(Path(o).name.split(\"_\")[1]))\n",
    "    videoframes_dict[k] = new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for k,v in videoframes_dict.items(): res.append({\"fname\":f\"{k}.mp4\", \"face_crop_fnames\":v})\n",
    "face_crop_fnames_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>face_crop_fnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fopjiyxiqd.mp4</td>\n",
       "      <td>[dfdc_train_part_0/fopjiyxiqd/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zqtvyuoabj.mp4</td>\n",
       "      <td>[dfdc_train_part_0/zqtvyuoabj/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dwkkqhxclz.mp4</td>\n",
       "      <td>[dfdc_train_part_0/dwkkqhxclz/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmmcypdfbr.mp4</td>\n",
       "      <td>[dfdc_train_part_0/rmmcypdfbr/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hkvcbcfulf.mp4</td>\n",
       "      <td>[dfdc_train_part_0/hkvcbcfulf/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname                                   face_crop_fnames\n",
       "0  fopjiyxiqd.mp4  [dfdc_train_part_0/fopjiyxiqd/frame_1_30.jpg, ...\n",
       "1  zqtvyuoabj.mp4  [dfdc_train_part_0/zqtvyuoabj/frame_1_30.jpg, ...\n",
       "2  dwkkqhxclz.mp4  [dfdc_train_part_0/dwkkqhxclz/frame_1_30.jpg, ...\n",
       "3  rmmcypdfbr.mp4  [dfdc_train_part_0/rmmcypdfbr/frame_1_30.jpg, ...\n",
       "4  hkvcbcfulf.mp4  [dfdc_train_part_0/hkvcbcfulf/frame_1_30.jpg, ..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_crop_fnames_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "source2fakes = defaultdict(list)\n",
    "for _, row in detections_df.iterrows():\n",
    "    if row['source'] != row['fname']: source2fakes[row['source']].append(row['fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of original videos: 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total # of original videos: {len(source2fakes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Compare original and fake frame pixels\n",
    "\n",
    "It is discussed in forums that there is at least 1 pixel change in every video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_itemlist(il):\n",
    "    n = int(np.ceil(np.sqrt(len(il))))\n",
    "    axes = subplots(n,n).flatten()\n",
    "    for i, ax in zip(range(len(il)), axes): il[i].show(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identical_idxs_dict = {}\n",
    "# for source, fakes in source2fakes.items(): \n",
    "#     # get original frames itemlist\n",
    "#     video_name = Path(source).stem\n",
    "#     frame_fnames = videoframes_dict[video_name]\n",
    "#     original_il = ImageList([croppped_path/o for o in frame_fnames])\n",
    "\n",
    "#     # detect if there are unchanged fake frame  \n",
    "#     identical_idxs = []\n",
    "#     for i in range(len(fakes)):\n",
    "#         video_name = Path(fakes[i]).stem\n",
    "#         frame_fnames = videoframes_dict[video_name]\n",
    "#         fake_il = ImageList([croppped_path/o for o in frame_fnames])\n",
    "#         identical_idxs.append((np.where([torch.equal(orig_frame.data, fake_frame.data) \n",
    "#                            for orig_frame, fake_frame in zip(original_il, fake_il)])))\n",
    "    \n",
    "#     # \n",
    "#     identical_idxs_dict[source] = identical_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_itemlist(original_il)\n",
    "# plot_itemlist(fake_il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_no = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path/'dfdc_training_csv', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_df(part_no):\n",
    "    # get cropped files\n",
    "    detections_df = pd.read_csv(detections_path/f'part_{part_no}_retina_detections.csv')\n",
    "    cropped_files = get_files(croppped_path/f'dfdc_train_part_{part_no}', extensions=['.jpg'], recurse=True)\n",
    "\n",
    "    # collect video frames relative to parent cropped faces dir\n",
    "    videoframes_dict = defaultdict(list)\n",
    "    for o in cropped_files: videoframes_dict[o.parent.name].append(\"/\".join(str(o).split(\"/\")[-3:]))\n",
    "\n",
    "    # sort by frame #\n",
    "    for k,v in videoframes_dict.items(): \n",
    "        new_v = sorted(v, key=lambda o: int(Path(o).name.split(\"_\")[1]))\n",
    "        videoframes_dict[k] = new_v\n",
    "\n",
    "    # create dataframe\n",
    "    res = []\n",
    "    for k,v in videoframes_dict.items(): res.append({\"fname\":f\"{k}.mp4\", \"face_crop_fnames\":v})\n",
    "    face_crop_fnames_df = pd.DataFrame(res)\n",
    "\n",
    "    train_df = detections_df.merge(face_crop_fnames_df, on='fname', how='inner')\n",
    "    train_df.to_csv(data_path/f'dfdc_training_csv/part_{part_no}_training.csv', index=False)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = list(map(str, range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for part in parts: create_training_df(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "      <th>face_crop_fnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zumqqvixhu.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/zumqqvixhu/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zrrncwxmdc.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/zrrncwxmdc/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/hntguogkqd/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slhkaosehs.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/slhkaosehs/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qeefkatpus.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/qeefkatpus/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>nfsztvjqpk.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>nymodlmxni.mp4</td>\n",
       "      <td>nymodlmxni.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[845, 107, 963...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/nfsztvjqpk/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>wlehzhjppc.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[851, 83, 955,...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/wlehzhjppc/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[851, 83, 955,...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/zfobicuigx/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[880, 105, 100...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/qjdtgggqym/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>bfeewgzrbr.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[880, 105, 100...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/bfeewgzrbr/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fname label  split        original          source  \\\n",
       "0     zumqqvixhu.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "1     zrrncwxmdc.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "2     hntguogkqd.mp4  REAL  train             NaN  hntguogkqd.mp4   \n",
       "3     slhkaosehs.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "4     qeefkatpus.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "...              ...   ...    ...             ...             ...   \n",
       "1694  nfsztvjqpk.mp4  FAKE  train  nymodlmxni.mp4  nymodlmxni.mp4   \n",
       "1695  wlehzhjppc.mp4  FAKE  train  zfobicuigx.mp4  zfobicuigx.mp4   \n",
       "1696  zfobicuigx.mp4  REAL  train             NaN  zfobicuigx.mp4   \n",
       "1697  qjdtgggqym.mp4  REAL  train             NaN  qjdtgggqym.mp4   \n",
       "1698  bfeewgzrbr.mp4  FAKE  train  qjdtgggqym.mp4  qjdtgggqym.mp4   \n",
       "\n",
       "              size                                    face_detections  \\\n",
       "0     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "1     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "2     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "3     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "4     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "...            ...                                                ...   \n",
       "1694  (1080, 1920)  [{'frame_no': 0, 'detections': [[845, 107, 963...   \n",
       "1695  (1080, 1920)  [{'frame_no': 0, 'detections': [[851, 83, 955,...   \n",
       "1696  (1080, 1920)  [{'frame_no': 0, 'detections': [[851, 83, 955,...   \n",
       "1697  (1080, 1920)  [{'frame_no': 0, 'detections': [[880, 105, 100...   \n",
       "1698  (1080, 1920)  [{'frame_no': 0, 'detections': [[880, 105, 100...   \n",
       "\n",
       "      n_frames  sample_freq  len_video  \\\n",
       "0           30           10        299   \n",
       "1           30           10        299   \n",
       "2           30           10        299   \n",
       "3           30           10        299   \n",
       "4           30           10        299   \n",
       "...        ...          ...        ...   \n",
       "1694        30           10        300   \n",
       "1695        30           10        300   \n",
       "1696        30           10        300   \n",
       "1697        30           10        300   \n",
       "1698        30           10        300   \n",
       "\n",
       "                                       face_crop_fnames  \n",
       "0     [dfdc_train_part_1/zumqqvixhu/frame_1_30.jpg, ...  \n",
       "1     [dfdc_train_part_1/zrrncwxmdc/frame_1_30.jpg, ...  \n",
       "2     [dfdc_train_part_1/hntguogkqd/frame_1_30.jpg, ...  \n",
       "3     [dfdc_train_part_1/slhkaosehs/frame_1_30.jpg, ...  \n",
       "4     [dfdc_train_part_1/qeefkatpus/frame_1_30.jpg, ...  \n",
       "...                                                 ...  \n",
       "1694  [dfdc_train_part_1/nfsztvjqpk/frame_1_30.jpg, ...  \n",
       "1695  [dfdc_train_part_1/wlehzhjppc/frame_1_30.jpg, ...  \n",
       "1696  [dfdc_train_part_1/zfobicuigx/frame_1_30.jpg, ...  \n",
       "1697  [dfdc_train_part_1/qjdtgggqym/frame_1_30.jpg, ...  \n",
       "1698  [dfdc_train_part_1/bfeewgzrbr/frame_1_30.jpg, ...  \n",
       "\n",
       "[1699 rows x 11 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepfake]",
   "language": "python",
   "name": "conda-env-deepfake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
