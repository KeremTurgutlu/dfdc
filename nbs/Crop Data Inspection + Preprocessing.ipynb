{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfdc.core.core import *\n",
    "from dfdc.core.video_core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/ubuntu/data/dfdc/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_path = data_path/'dfdc_face_detections'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50,\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_face_detections/part_38_retina_detections.csv'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detections_path.ls()), detections_path.ls()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "croppped_path = data_path/'dfdc_cropped_faces'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_37'))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(croppped_path.ls()), croppped_path.ls()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Read detections df and crop files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfdc.core.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_no = '4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections_df = read_face_detection_df(detections_path/f'part_{part_no}_retina_detections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oyixebfpcl.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shclgsfxtj.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mutuhmwjdv.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rohakxryar.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fpiybwcszz.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>bgpoldvzrh.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[1300, 351, 15...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname label  split        original          source          size  \\\n",
       "0  oyixebfpcl.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "1  shclgsfxtj.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "2  mutuhmwjdv.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "3  rohakxryar.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "4  fpiybwcszz.mp4  FAKE  train  bgpoldvzrh.mp4  bgpoldvzrh.mp4  (1080, 1920)   \n",
       "\n",
       "                                     face_detections  n_frames  sample_freq  \\\n",
       "0  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "1  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "2  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "3  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "4  [{'frame_no': 0, 'detections': [[1300, 351, 15...        30           10   \n",
       "\n",
       "   len_video  \n",
       "0        299  \n",
       "1        299  \n",
       "2        299  \n",
       "3        299  \n",
       "4        299  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1701, 10)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detections_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dets in detections_df['face_detections']: \n",
    "    if [o['detections'] for o in dets] == []: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_part_path = croppped_path/f'dfdc_train_part_{part_no}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_dirs = [o for o in cropped_part_path.ls() if (o.ls()) == []] # no detections - false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_files = get_files(cropped_part_path, extensions=['.jpg'], recurse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40087"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cropped_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_22_30.jpg'),\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_14_30.jpg'),\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_10_30.jpg'),\n",
       " PosixPath('/home/ubuntu/data/dfdc/dfdc_cropped_faces/dfdc_train_part_4/bmgcyjggxe/frame_20_30.jpg')]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cropped_files[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Collect and sort frames for each video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoframes_dict = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in cropped_files: videoframes_dict[o.parent.name].append(\"/\".join(str(o).split(\"/\")[-3:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1544"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(videoframes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in videoframes_dict.items(): \n",
    "    new_v = sorted(v, key=lambda o: int(Path(o).name.split(\"_\")[1]))\n",
    "    videoframes_dict[k] = new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for k,v in videoframes_dict.items(): res.append({\"fname\":f\"{k}.mp4\", \"face_crop_fnames\":v})\n",
    "face_crop_fnames_df = pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>face_crop_fnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fopjiyxiqd.mp4</td>\n",
       "      <td>[dfdc_train_part_0/fopjiyxiqd/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zqtvyuoabj.mp4</td>\n",
       "      <td>[dfdc_train_part_0/zqtvyuoabj/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dwkkqhxclz.mp4</td>\n",
       "      <td>[dfdc_train_part_0/dwkkqhxclz/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rmmcypdfbr.mp4</td>\n",
       "      <td>[dfdc_train_part_0/rmmcypdfbr/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hkvcbcfulf.mp4</td>\n",
       "      <td>[dfdc_train_part_0/hkvcbcfulf/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname                                   face_crop_fnames\n",
       "0  fopjiyxiqd.mp4  [dfdc_train_part_0/fopjiyxiqd/frame_1_30.jpg, ...\n",
       "1  zqtvyuoabj.mp4  [dfdc_train_part_0/zqtvyuoabj/frame_1_30.jpg, ...\n",
       "2  dwkkqhxclz.mp4  [dfdc_train_part_0/dwkkqhxclz/frame_1_30.jpg, ...\n",
       "3  rmmcypdfbr.mp4  [dfdc_train_part_0/rmmcypdfbr/frame_1_30.jpg, ...\n",
       "4  hkvcbcfulf.mp4  [dfdc_train_part_0/hkvcbcfulf/frame_1_30.jpg, ..."
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_crop_fnames_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "source2fakes = defaultdict(list)\n",
    "for _, row in detections_df.iterrows():\n",
    "    if row['source'] != row['fname']: source2fakes[row['source']].append(row['fname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of original videos: 86\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total # of original videos: {len(source2fakes)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Compare original and fake frame pixels\n",
    "\n",
    "It is discussed in forums that there is at least 1 pixel change in every video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_itemlist(il):\n",
    "    n = int(np.ceil(np.sqrt(len(il))))\n",
    "    axes = subplots(n,n).flatten()\n",
    "    for i, ax in zip(range(len(il)), axes): il[i].show(ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identical_idxs_dict = {}\n",
    "# for source, fakes in source2fakes.items(): \n",
    "#     # get original frames itemlist\n",
    "#     video_name = Path(source).stem\n",
    "#     frame_fnames = videoframes_dict[video_name]\n",
    "#     original_il = ImageList([croppped_path/o for o in frame_fnames])\n",
    "\n",
    "#     # detect if there are unchanged fake frame  \n",
    "#     identical_idxs = []\n",
    "#     for i in range(len(fakes)):\n",
    "#         video_name = Path(fakes[i]).stem\n",
    "#         frame_fnames = videoframes_dict[video_name]\n",
    "#         fake_il = ImageList([croppped_path/o for o in frame_fnames])\n",
    "#         identical_idxs.append((np.where([torch.equal(orig_frame.data, fake_frame.data) \n",
    "#                            for orig_frame, fake_frame in zip(original_il, fake_il)])))\n",
    "    \n",
    "#     # \n",
    "#     identical_idxs_dict[source] = identical_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_itemlist(original_il)\n",
    "# plot_itemlist(fake_il)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_no = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(data_path/'dfdc_training_csv', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_df(part_no):\n",
    "    # get cropped files\n",
    "    detections_df = pd.read_csv(detections_path/f'part_{part_no}_retina_detections.csv')\n",
    "    cropped_files = get_files(croppped_path/f'dfdc_train_part_{part_no}', extensions=['.jpg'], recurse=True)\n",
    "\n",
    "    # collect video frames relative to parent cropped faces dir\n",
    "    videoframes_dict = defaultdict(list)\n",
    "    for o in cropped_files: videoframes_dict[o.parent.name].append(\"/\".join(str(o).split(\"/\")[-3:]))\n",
    "\n",
    "    # sort by frame #\n",
    "    for k,v in videoframes_dict.items(): \n",
    "        new_v = sorted(v, key=lambda o: int(Path(o).name.split(\"_\")[1]))\n",
    "        videoframes_dict[k] = new_v\n",
    "\n",
    "    # create dataframe\n",
    "    res = []\n",
    "    for k,v in videoframes_dict.items(): res.append({\"fname\":f\"{k}.mp4\", \"face_crop_fnames\":v})\n",
    "    face_crop_fnames_df = pd.DataFrame(res)\n",
    "\n",
    "    train_df = detections_df.merge(face_crop_fnames_df, on='fname', how='inner')\n",
    "    train_df.to_csv(data_path/f'dfdc_training_csv/part_{part_no}_training.csv', index=False)\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "parts = list(map(str, range(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for part in parts: create_training_df(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "      <th>face_crop_fnames</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zumqqvixhu.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/zumqqvixhu/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zrrncwxmdc.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/zrrncwxmdc/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/hntguogkqd/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>slhkaosehs.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/slhkaosehs/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qeefkatpus.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>hntguogkqd.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[894, 135, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>299</td>\n",
       "      <td>[dfdc_train_part_1/qeefkatpus/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>nfsztvjqpk.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>nymodlmxni.mp4</td>\n",
       "      <td>nymodlmxni.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[845, 107, 963...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/nfsztvjqpk/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>wlehzhjppc.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[851, 83, 955,...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/wlehzhjppc/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zfobicuigx.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[851, 83, 955,...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/zfobicuigx/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>REAL</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[880, 105, 100...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/qjdtgggqym/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>bfeewgzrbr.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>qjdtgggqym.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[880, 105, 100...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "      <td>[dfdc_train_part_1/bfeewgzrbr/frame_1_30.jpg, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1699 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               fname label  split        original          source  \\\n",
       "0     zumqqvixhu.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "1     zrrncwxmdc.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "2     hntguogkqd.mp4  REAL  train             NaN  hntguogkqd.mp4   \n",
       "3     slhkaosehs.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "4     qeefkatpus.mp4  FAKE  train  hntguogkqd.mp4  hntguogkqd.mp4   \n",
       "...              ...   ...    ...             ...             ...   \n",
       "1694  nfsztvjqpk.mp4  FAKE  train  nymodlmxni.mp4  nymodlmxni.mp4   \n",
       "1695  wlehzhjppc.mp4  FAKE  train  zfobicuigx.mp4  zfobicuigx.mp4   \n",
       "1696  zfobicuigx.mp4  REAL  train             NaN  zfobicuigx.mp4   \n",
       "1697  qjdtgggqym.mp4  REAL  train             NaN  qjdtgggqym.mp4   \n",
       "1698  bfeewgzrbr.mp4  FAKE  train  qjdtgggqym.mp4  qjdtgggqym.mp4   \n",
       "\n",
       "              size                                    face_detections  \\\n",
       "0     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "1     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "2     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "3     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "4     (1080, 1920)  [{'frame_no': 0, 'detections': [[894, 135, 105...   \n",
       "...            ...                                                ...   \n",
       "1694  (1080, 1920)  [{'frame_no': 0, 'detections': [[845, 107, 963...   \n",
       "1695  (1080, 1920)  [{'frame_no': 0, 'detections': [[851, 83, 955,...   \n",
       "1696  (1080, 1920)  [{'frame_no': 0, 'detections': [[851, 83, 955,...   \n",
       "1697  (1080, 1920)  [{'frame_no': 0, 'detections': [[880, 105, 100...   \n",
       "1698  (1080, 1920)  [{'frame_no': 0, 'detections': [[880, 105, 100...   \n",
       "\n",
       "      n_frames  sample_freq  len_video  \\\n",
       "0           30           10        299   \n",
       "1           30           10        299   \n",
       "2           30           10        299   \n",
       "3           30           10        299   \n",
       "4           30           10        299   \n",
       "...        ...          ...        ...   \n",
       "1694        30           10        300   \n",
       "1695        30           10        300   \n",
       "1696        30           10        300   \n",
       "1697        30           10        300   \n",
       "1698        30           10        300   \n",
       "\n",
       "                                       face_crop_fnames  \n",
       "0     [dfdc_train_part_1/zumqqvixhu/frame_1_30.jpg, ...  \n",
       "1     [dfdc_train_part_1/zrrncwxmdc/frame_1_30.jpg, ...  \n",
       "2     [dfdc_train_part_1/hntguogkqd/frame_1_30.jpg, ...  \n",
       "3     [dfdc_train_part_1/slhkaosehs/frame_1_30.jpg, ...  \n",
       "4     [dfdc_train_part_1/qeefkatpus/frame_1_30.jpg, ...  \n",
       "...                                                 ...  \n",
       "1694  [dfdc_train_part_1/nfsztvjqpk/frame_1_30.jpg, ...  \n",
       "1695  [dfdc_train_part_1/wlehzhjppc/frame_1_30.jpg, ...  \n",
       "1696  [dfdc_train_part_1/zfobicuigx/frame_1_30.jpg, ...  \n",
       "1697  [dfdc_train_part_1/qjdtgggqym/frame_1_30.jpg, ...  \n",
       "1698  [dfdc_train_part_1/bfeewgzrbr/frame_1_30.jpg, ...  \n",
       "\n",
       "[1699 rows x 11 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepfake]",
   "language": "python",
   "name": "conda-env-deepfake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
