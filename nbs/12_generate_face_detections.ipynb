{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cli command for face detection with RetinaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp face_detection.generate_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastscript import call_parse, Param\n",
    "from fastai.imports import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dfdc.core.video_core import *\n",
    "from dfdc.face_detection.bbox_utils import *\n",
    "from dfdc.face_detection.retinaface import *\n",
    "from fastai.data_block import get_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `generate_face_detections()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@call_parse\n",
    "def generate_face_detections(video_directory:Param(\"Directory of videos\", type=str), \n",
    "                            dest_fname:Param(\"Destination to save the detection results dataframe\", type=str), \n",
    "                            freq:Param(\"Sample frequency for reading videos\", type=int), \n",
    "                            modelname:Param(\"Detection model backbone\", type=str),\n",
    "                            confidence_threshold:Param(\"confidence_threshold\", type=float) = 0.5,\n",
    "                            top_k:Param(\"top_k before nms\", type=int) = 5,\n",
    "                            nms_threshold:Param(\"nms_threshold\", type=float) = 0.5,\n",
    "                            keep_top_k:Param(\"keep_top_k after nms\", type=int) = 5):\n",
    "    \n",
    "    # retinaface model arguments\n",
    "    model_args = dict(confidence_threshold = confidence_threshold, \n",
    "                      top_k = top_k,\n",
    "                      nms_threshold = nms_threshold,\n",
    "                      keep_top_k = keep_top_k)\n",
    "    \n",
    "    # load model\n",
    "    model, cfg = get_model(modelname)\n",
    "\n",
    "    # get all video files under dir\n",
    "    video_files = get_files(video_directory, extensions=['.mp4'])\n",
    "\n",
    "    # get face detections\n",
    "    res = []\n",
    "    for fname in tqdm(video_files):\n",
    "        # get face detections per video\n",
    "        sz = cfg['image_size']\n",
    "        t, t_raw, (H,W), len_video = get_decord_video_batch_cpu(fname, freq, sz, retinaface_stats)\n",
    "        bboxes, landmarks = predict(model, t, sz, cfg, **model_args)\n",
    "        orig_bboxes = bboxes_to_original_scale(bboxes, H, W, sz)\n",
    "        orig_landmarks = landmarks_to_original_scale(landmarks, H, W, sz)\n",
    "        orig_bboxes = [o.tolist() for o in orig_bboxes]\n",
    "        orig_landmarks = [o.tolist() for o in orig_landmarks]\n",
    "\n",
    "        # generate structured output\n",
    "        video_res = {}\n",
    "        video_res[\"fname\"] = fname.name\n",
    "        video_res[\"size\"] = (H, W)\n",
    "        video_res[\"face_detections\"] = [{\"frame_no\":frame_no, \"detections\":detections, \"landmarks\":landmarks}\n",
    "                                            for frame_no, detections, landmarks in \n",
    "                                            zip(range(0, len_video, freq), orig_bboxes, orig_landmarks)]\n",
    "        video_res[\"n_frames\"] = t.shape[0]\n",
    "        video_res[\"sample_freq\"] = freq\n",
    "        video_res[\"len_video\"] = len_video\n",
    "        res.append(video_res)\n",
    "    \n",
    "    # save results\n",
    "    df = pd.DataFrame(res)\n",
    "    df.to_csv(dest_fname, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"mobilenet\"\n",
    "video_directory = \"/home/ubuntu/data/dfdc/dfdc_train/dfdc_train_part_48/\"\n",
    "dest_fname = \"/home/ubuntu/data/dfdc/dfdc_face_detections/part_48_retina_detections.csv\"\n",
    "freq = 10\n",
    "model_args = dict(confidence_threshold = 0.5, top_k = 5, nms_threshold = 0.5, keep_top_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_face_detections(video_directory, dest_fname, freq, \"mobilenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dest_fname)\n",
    "df.face_detections = (df.face_detections.apply(lambda o: json.loads(o.replace(\"'\", '\"'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'frame_no': 0, 'detections': [[809, 211, 943, 317]]},\n",
       " {'frame_no': 10, 'detections': [[808, 211, 943, 317]]},\n",
       " {'frame_no': 20, 'detections': []},\n",
       " {'frame_no': 30, 'detections': [[796, 208, 907, 297]]},\n",
       " {'frame_no': 40, 'detections': []},\n",
       " {'frame_no': 50, 'detections': []},\n",
       " {'frame_no': 60, 'detections': []},\n",
       " {'frame_no': 70, 'detections': []},\n",
       " {'frame_no': 80, 'detections': [[815, 221, 934, 314]]},\n",
       " {'frame_no': 90, 'detections': []},\n",
       " {'frame_no': 100, 'detections': [[815, 219, 932, 310]]},\n",
       " {'frame_no': 110, 'detections': [[807, 213, 942, 319]]},\n",
       " {'frame_no': 120, 'detections': [[812, 207, 936, 305]]},\n",
       " {'frame_no': 130, 'detections': []},\n",
       " {'frame_no': 140, 'detections': [[784, 220, 926, 331]]},\n",
       " {'frame_no': 150, 'detections': []},\n",
       " {'frame_no': 160, 'detections': []},\n",
       " {'frame_no': 170, 'detections': []},\n",
       " {'frame_no': 180, 'detections': []},\n",
       " {'frame_no': 190, 'detections': [[818, 209, 970, 324]]},\n",
       " {'frame_no': 200, 'detections': [[797, 208, 948, 324]]},\n",
       " {'frame_no': 210, 'detections': [[817, 216, 940, 314]]},\n",
       " {'frame_no': 220, 'detections': [[811, 214, 943, 318]]},\n",
       " {'frame_no': 230, 'detections': [[815, 202, 942, 303]]},\n",
       " {'frame_no': 240, 'detections': [[809, 205, 939, 307]]},\n",
       " {'frame_no': 250, 'detections': [[817, 211, 939, 307]]},\n",
       " {'frame_no': 260, 'detections': [[810, 209, 939, 311]]},\n",
       " {'frame_no': 270, 'detections': []},\n",
       " {'frame_no': 280, 'detections': [[810, 211, 933, 308]]},\n",
       " {'frame_no': 290, 'detections': [[813, 207, 937, 303]]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['face_detections'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 001 - extract_faces.ipynb.\n",
      "Converted 002 - face_detection_retinaface.ipynb.\n",
      "Converted 003 - save_face_crops.ipynb.\n",
      "Converted 004 - tl_baseline.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 01_video_core.ipynb.\n",
      "Converted 10_bbox_utils.ipynb.\n",
      "Converted 11_retinaface_detection.ipynb.\n",
      "Converted 12_generate_face_detections.ipynb.\n",
      "Converted 13_save_cropped_faces.ipynb.\n",
      "Converted 21_baseline_model.ipynb.\n",
      "Converted index.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepfake]",
   "language": "python",
   "name": "conda-env-deepfake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
