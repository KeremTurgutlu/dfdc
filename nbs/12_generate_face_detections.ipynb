{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cli command for face detection with RetinaFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default_exp face_detection.generate_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastscript import call_parse, Param\n",
    "from fastai.imports import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from dfdc.core.video_core import *\n",
    "from dfdc.face_detection.bbox_utils import *\n",
    "from dfdc.face_detection.retinaface import *\n",
    "from fastai.data_block import get_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `generate_face_detections()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def generate_face_detections(video_files_txt:Param(\"csv or txt with list of video paths\", type=str), \n",
    "                            freq:Param(\"Sample frequency for reading videos\", type=int), \n",
    "                            modelname:Param(\"Detection model backbone\", type=str),\n",
    "                            confidence_threshold:Param(\"confidence_threshold\", type=float) = 0.5,\n",
    "                            top_k:Param(\"top_k before nms\", type=int) = 5,\n",
    "                            nms_threshold:Param(\"nms_threshold\", type=float) = 0.5,\n",
    "                            keep_top_k:Param(\"keep_top_k after nms\", type=int) = 5):\n",
    "    \n",
    "    # retinaface model arguments\n",
    "    model_args = dict(confidence_threshold = confidence_threshold, \n",
    "                      top_k = top_k,\n",
    "                      nms_threshold = nms_threshold,\n",
    "                      keep_top_k = keep_top_k)\n",
    "    \n",
    "    # load model\n",
    "    model, cfg = get_model(modelname)\n",
    "\n",
    "    # get all video files under dir\n",
    "    video_files = list(map(lambda o: Path(o), list(pd.read_csv(video_files_txt).iloc[:,0].values)))\n",
    "\n",
    "    # get face detections\n",
    "    res = []\n",
    "    for fname in tqdm(video_files):\n",
    "        # get face detections per video\n",
    "        sz = cfg['image_size']\n",
    "        t, t_raw, (H,W), len_video = get_decord_video_batch_cpu(fname, freq, sz, retinaface_stats)\n",
    "        bboxes, landmarks = predict(model, t, sz, cfg, **model_args)\n",
    "        orig_bboxes = bboxes_to_original_scale(bboxes, H, W, sz)\n",
    "        orig_landmarks = landmarks_to_original_scale(landmarks, H, W, sz)\n",
    "        orig_bboxes = [o.tolist() for o in orig_bboxes]\n",
    "        orig_landmarks = [o.tolist() for o in orig_landmarks]\n",
    "\n",
    "        # generate structured output\n",
    "        video_res = {}\n",
    "        video_res[\"fname\"] = fname.name\n",
    "        video_res[\"size\"] = (H, W)\n",
    "        video_res[\"face_detections\"] = [{\"frame_no\":frame_no, \"detections\":detections, \"landmarks\":landmarks}\n",
    "                                            for frame_no, detections, landmarks in \n",
    "                                            zip(range(0, len_video, freq), orig_bboxes, orig_landmarks)]\n",
    "        video_res[\"n_frames\"] = t.shape[0]\n",
    "        video_res[\"sample_freq\"] = freq\n",
    "        video_res[\"len_video\"] = len_video\n",
    "        res.append(video_res)\n",
    "    \n",
    "    # generate dataframe\n",
    "    df = pd.DataFrame(res)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dfdc.core.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_no = 48\n",
    "modelname = \"mobilenet\"\n",
    "data_path = Path(\"/home/ubuntu/data/dfdc/\")\n",
    "video_path = Path(data_path/f\"dfdc_train/dfdc_train_part_{part_no}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf = read_metadata(get_files(video_path, extensions=['.json'], recurse=True)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files_txt = video_path/\"original_video_files.txt\"\n",
    "_ = get_original_video_list(video_path, metadf, video_files_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_fname = data_path/f\"dfdc_face_detections/part_{part_no}_retina_detections.csv\"\n",
    "freq = 10\n",
    "model_args = dict(confidence_threshold = 0.5, top_k = 5, nms_threshold = 0.5, keep_top_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model from /home/ubuntu/git/dfdc/local_misc/pytorch_retinaface/weights/mobilenet0.25_Final.pth\n",
      "remove prefix 'module.'\n",
      "Missing keys:0\n",
      "Unused checkpoint keys:0\n",
      "Used keys:300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 422/422 [06:46<00:00,  1.04it/s]\n"
     ]
    }
   ],
   "source": [
    "df = generate_face_detections(video_files_txt, freq, \"mobilenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadf[\"source\"] = metadf.apply(lambda o: o['original'] \n",
    "                                if type(o['original']) == str else o['fname'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={\"fname\":\"source\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not face_detections_df.len_video.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "      <th>source</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>noagmcpxfb.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>dgtdgrzifi.mp4</td>\n",
       "      <td>dgtdgrzifi.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[506, 976, 636...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qdumndmniy.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>dgtdgrzifi.mp4</td>\n",
       "      <td>dgtdgrzifi.mp4</td>\n",
       "      <td>(1920, 1080)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[506, 976, 636...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname label  split        original          source          size  \\\n",
       "0  noagmcpxfb.mp4  FAKE  train  dgtdgrzifi.mp4  dgtdgrzifi.mp4  (1920, 1080)   \n",
       "1  qdumndmniy.mp4  FAKE  train  dgtdgrzifi.mp4  dgtdgrzifi.mp4  (1920, 1080)   \n",
       "\n",
       "                                     face_detections  n_frames  sample_freq  \\\n",
       "0  [{'frame_no': 0, 'detections': [[506, 976, 636...        30           10   \n",
       "1  [{'frame_no': 0, 'detections': [[506, 976, 636...        30           10   \n",
       "\n",
       "   len_video  \n",
       "0        300  \n",
       "1        300  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detections_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelname = \"mobilenet\"\n",
    "video_directory = \"/home/ubuntu/data/dfdc/dfdc_train/dfdc_train_part_48/\"\n",
    "dest_fname = \"/home/ubuntu/data/dfdc/dfdc_face_detections/part_48_retina_detections.csv\"\n",
    "freq = 10\n",
    "model_args = dict(confidence_threshold = 0.5, top_k = 5, nms_threshold = 0.5, keep_top_k = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = generate_face_detections(video_directory, dest_fname, freq, \"mobilenet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dest_fname)\n",
    "df.face_detections = (df.face_detections.apply(lambda o: json.loads(o.replace(\"'\", '\"'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'frame_no': 0, 'detections': [[809, 211, 943, 317]]},\n",
       " {'frame_no': 10, 'detections': [[808, 211, 943, 317]]},\n",
       " {'frame_no': 20, 'detections': []},\n",
       " {'frame_no': 30, 'detections': [[796, 208, 907, 297]]},\n",
       " {'frame_no': 40, 'detections': []},\n",
       " {'frame_no': 50, 'detections': []},\n",
       " {'frame_no': 60, 'detections': []},\n",
       " {'frame_no': 70, 'detections': []},\n",
       " {'frame_no': 80, 'detections': [[815, 221, 934, 314]]},\n",
       " {'frame_no': 90, 'detections': []},\n",
       " {'frame_no': 100, 'detections': [[815, 219, 932, 310]]},\n",
       " {'frame_no': 110, 'detections': [[807, 213, 942, 319]]},\n",
       " {'frame_no': 120, 'detections': [[812, 207, 936, 305]]},\n",
       " {'frame_no': 130, 'detections': []},\n",
       " {'frame_no': 140, 'detections': [[784, 220, 926, 331]]},\n",
       " {'frame_no': 150, 'detections': []},\n",
       " {'frame_no': 160, 'detections': []},\n",
       " {'frame_no': 170, 'detections': []},\n",
       " {'frame_no': 180, 'detections': []},\n",
       " {'frame_no': 190, 'detections': [[818, 209, 970, 324]]},\n",
       " {'frame_no': 200, 'detections': [[797, 208, 948, 324]]},\n",
       " {'frame_no': 210, 'detections': [[817, 216, 940, 314]]},\n",
       " {'frame_no': 220, 'detections': [[811, 214, 943, 318]]},\n",
       " {'frame_no': 230, 'detections': [[815, 202, 942, 303]]},\n",
       " {'frame_no': 240, 'detections': [[809, 205, 939, 307]]},\n",
       " {'frame_no': 250, 'detections': [[817, 211, 939, 307]]},\n",
       " {'frame_no': 260, 'detections': [[810, 209, 939, 311]]},\n",
       " {'frame_no': 270, 'detections': []},\n",
       " {'frame_no': 280, 'detections': [[810, 211, 933, 308]]},\n",
       " {'frame_no': 290, 'detections': [[813, 207, 937, 303]]}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['face_detections'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.export import notebook2script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 001 - extract_faces.ipynb.\n",
      "Converted 002 - face_detection_retinaface.ipynb.\n",
      "Converted 003 - save_face_crops.ipynb.\n",
      "Converted 004 - tl_baseline.ipynb.\n",
      "Converted 00_core.ipynb.\n",
      "Converted 01_video_core.ipynb.\n",
      "Converted 10_bbox_utils.ipynb.\n",
      "Converted 11_retinaface_detection.ipynb.\n",
      "Converted 12_generate_face_detections.ipynb.\n",
      "Converted 13_save_cropped_faces.ipynb.\n",
      "Converted 14_detect_crop_save.ipynb.\n",
      "Converted 20_datasets.ipynb.\n",
      "Converted 21_single_frame_model.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted inspect original fake pairs for face detection.ipynb.\n"
     ]
    }
   ],
   "source": [
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepfake]",
   "language": "python",
   "name": "conda-env-deepfake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
