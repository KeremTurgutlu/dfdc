{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crop faces from videos by detections by `face_detections_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/home/ubuntu/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = data_path/\"dfdc_train_part_49\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = get_files(\"/home/ubuntu/data/dfdc_train_part_49/\", extensions=['.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_files = get_files(\"/home/ubuntu/data/dfdc_train_part_49/\", extensions=['.mp4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_metadata(fn):\n",
    "    metadf = pd.read_json(fn).T.reset_index()\n",
    "    metadf.columns = ['fname','label','split','original']\n",
    "    return metadf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadf = read_metadata(metadata[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dwwytkheyx.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>nlcqykqsdp.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bdsxxaamze.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>xzmplldajk.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tfceaqvefa.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>zkksmnscsf.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lurozpmsqd.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>urbulrzowx.mp4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jvlvkijuwa.mp4</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>train</td>\n",
       "      <td>wvnjcwevzo.mp4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname label  split        original\n",
       "0  dwwytkheyx.mp4  FAKE  train  nlcqykqsdp.mp4\n",
       "1  bdsxxaamze.mp4  FAKE  train  xzmplldajk.mp4\n",
       "2  tfceaqvefa.mp4  FAKE  train  zkksmnscsf.mp4\n",
       "3  lurozpmsqd.mp4  FAKE  train  urbulrzowx.mp4\n",
       "4  jvlvkijuwa.mp4  FAKE  train  wvnjcwevzo.mp4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>original</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FAKE</th>\n",
       "      <td>2619</td>\n",
       "      <td>2619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>REAL</th>\n",
       "      <td>515</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fname  original\n",
       "label                 \n",
       "FAKE    2619      2619\n",
       "REAL     515         0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadf.groupby(\"label\")[[\"fname\",'original']].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### face detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections_df = pd.read_csv(data_path/'dfdc_faces/part_49_retina_detections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_detections_df.face_detections = (face_detections_df.face_detections\n",
    "                                          .apply(lambda o: json.loads(o.replace(\"'\", '\"'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fname</th>\n",
       "      <th>size</th>\n",
       "      <th>face_detections</th>\n",
       "      <th>n_frames</th>\n",
       "      <th>sample_freq</th>\n",
       "      <th>len_video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yraysfvtgv.mp4</td>\n",
       "      <td>(1280, 720)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[290, 268, 398...</td>\n",
       "      <td>31</td>\n",
       "      <td>10</td>\n",
       "      <td>301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jidkzoagws.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[895, 172, 101...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uowiocuqqt.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[845, 265, 105...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sigtxuuutc.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[899, 139, 104...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>uzawooqxrq.mp4</td>\n",
       "      <td>(1080, 1920)</td>\n",
       "      <td>[{'frame_no': 0, 'detections': [[818, 146, 978...</td>\n",
       "      <td>30</td>\n",
       "      <td>10</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fname          size  \\\n",
       "0  yraysfvtgv.mp4   (1280, 720)   \n",
       "1  jidkzoagws.mp4  (1080, 1920)   \n",
       "2  uowiocuqqt.mp4  (1080, 1920)   \n",
       "3  sigtxuuutc.mp4  (1080, 1920)   \n",
       "4  uzawooqxrq.mp4  (1080, 1920)   \n",
       "\n",
       "                                     face_detections  n_frames  sample_freq  \\\n",
       "0  [{'frame_no': 0, 'detections': [[290, 268, 398...        31           10   \n",
       "1  [{'frame_no': 0, 'detections': [[895, 172, 101...        30           10   \n",
       "2  [{'frame_no': 0, 'detections': [[845, 265, 105...        30           10   \n",
       "3  [{'frame_no': 0, 'detections': [[899, 139, 104...        30           10   \n",
       "4  [{'frame_no': 0, 'detections': [[818, 146, 978...        30           10   \n",
       "\n",
       "   len_video  \n",
       "0        301  \n",
       "1        300  \n",
       "2        300  \n",
       "3        300  \n",
       "4        300  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "face_detections_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'(1280, 720)': 715, '(1080, 1920)': 2234, '(1920, 1080)': 185})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(face_detections_df['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### video utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decord import VideoReader\n",
    "from decord import cpu\n",
    "from decord.bridge import set_bridge\n",
    "set_bridge('torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_decord_video_batch_cpu(fname, sz, freq=10, stats=None):\n",
    "    \"get batch tensor for inference, original for cropping and H,W of video\"\n",
    "    video = VideoReader(str(fname), ctx=cpu())\n",
    "    t = video.get_batch(range(0, len(video), freq))\n",
    "    H,W = t.shape[2:]\n",
    "    if sz: t = F.interpolate(t.to(torch.float32), (sz,sz)).to(device)\n",
    "    if stats is not None: t -= stats\n",
    "    return (t, (H, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_bboxes(bboxes, H, W, sz):\n",
    "    \"rescale bbox prediction to original image sz\"\n",
    "    res = []\n",
    "    for bb in bboxes:\n",
    "        h_scale, w_scale = H/sz, W/sz\n",
    "        orig_bboxes = (bb*array([w_scale, h_scale, w_scale, h_scale])[None, ...]).astype(int)\n",
    "        res.append(orig_bboxes)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_bbox(bb, bb_scale, H,W):\n",
    "    \"rescale a bbox: (left, top, right, bottom) with a given scale parameter\"\n",
    "    left, top, right, bottom = bb\n",
    "    \n",
    "    cx,cy = (top + bottom)//2, (left + right)//2 \n",
    "    h,w = (bottom - top), (right - left)\n",
    "    sh, sw = int(h*bb_scale), int(w*bb_scale)\n",
    "\n",
    "    stop, sbottom = cx - sh//2, cx + sh//2\n",
    "    sleft, sright = cy - sw//2, cy + sw//2\n",
    "    stop, sleft, sbottom, sright = max(0, stop), max(0, sleft), min(H, sbottom), min(W, sright)    \n",
    "    return (sleft, stop, sright, sbottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save cropped faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/ubuntu/data/cropped_faces/dfdc_train_part_49')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dir to save images for all videos\n",
    "crop_path = data_path/\"cropped_faces\"/video_path.name\n",
    "os.makedirs(crop_path, exist_ok=True); crop_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/home/ubuntu/data/dfdc_train_part_49/yraysfvtgv.mp4'),\n",
       " PosixPath('/home/ubuntu/data/dfdc_train_part_49/jidkzoagws.mp4'),\n",
       " PosixPath('/home/ubuntu/data/dfdc_train_part_49/uowiocuqqt.mp4')]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_path.ls()[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save(self, fn:PathOrStr, mult=False):\n",
    "    \"Save the image to `fn`.\"\n",
    "    x = image2np(self.data*255 if mult else self.data).astype(np.uint8)\n",
    "    PIL.Image.fromarray(x).save(fn)\n",
    "Image.save = save # monkey patch\n",
    "\n",
    "def crop_and_save(path:PathOrStr, fname:PathOrStr, crop_path:PathOrStr, bboxes:List[List[List]],\n",
    "                  freq, total_frames):\n",
    "    \"\"\"\n",
    "    path: directory which has the video with fname\n",
    "    fname: filename of video \"xxxxx.mp4\"\n",
    "    crop_path: destination directory to save cropped images for video\n",
    "    bboxes: list of bbox coordinates for each sampled frame for video\n",
    "    freq: sample frequence used in bbox detection\n",
    "    total_frames: total number of frames sampled from video during detection    \n",
    "    \"\"\"\n",
    "    \n",
    "    # read sampled raw video\n",
    "    t, (H, W) = get_decord_video_batch_cpu(path/fname, None, freq, None)\n",
    "    # create directory to save crops\n",
    "    video_dir = crop_path/Path(fname).stem\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    # check if # of face detections are same as # of sampled frames\n",
    "    assert len(bboxes) == t.shape[0]\n",
    "    \n",
    "    for frame_no, (_frame, _bb) in enumerate(zip(t, bboxes)):\n",
    "        # don't try cropping if no detection is available for the frame\n",
    "        try: _bb[0] \n",
    "        except: continue\n",
    "        # naive: get first bbox, optionally rescale\n",
    "        left, top, right, bottom  = rescale_bbox(_bb[0], 1.3, H, W) \n",
    "        # crop and save\n",
    "        face_crop = Image(_frame[:, top:bottom, left:right])\n",
    "        # save with frame index (start from 1) and sequence length (total available frames)\n",
    "        save_path = video_dir/f\"frame_{frame_no+1}_{total_frames}.jpg\"\n",
    "        face_crop.save(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3134it [37:16,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(face_detections_df.iterrows()):\n",
    "    fname = row['fname']\n",
    "    face_detections = row['face_detections']\n",
    "    bboxes = [o['detections'] for o in face_detections]\n",
    "    freq = row['sample_freq']\n",
    "    total_frames = row['n_frames']\n",
    "    crop_and_save(video_path, fname, crop_path, bboxes, freq, total_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepfake]",
   "language": "python",
   "name": "conda-env-deepfake-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
