# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/21_single_frame_model.ipynb (unless otherwise specified).

__all__ = ['sort_dict', 'convert_cropped_files_todf', 'create_frame_label_df', 'SingleFrameDataset',
           'SingleFrameSampler', 'SingleFrameValidationDataset']

# Cell
from .dataset_utils import *
from fastai.vision import *
from tqdm import tqdm

# Cell
def sort_dict(d): return {k: v for k, v in sorted(d.items(), key=lambda item: item[1])}

# Cell
def convert_cropped_files_todf(cropped_files:List[PathOrStr]):
    "sort all frames by no and create dataframe for given videos"
    d = defaultdict(dict)
    for o in cropped_files:
        fname = o.parent.name
        frame_fname = str(o)
        frame_no = int(o.name.split("_")[1])
        d[fname][frame_fname] = frame_no

    res = []
    for video_fname, crop_fnames in d.items():
        frame_fnames = list(sort_dict(d[video_fname]).keys())
        res.append({"video_fname":video_fname, "frame_fnames":frame_fnames})
    return pd.DataFrame(res)


def create_frame_label_df(data_path, video_path, part_no):
    cropped_path = data_path/f'dfdc_cropped_faces/dfdc_train_part_{part_no}'
    cropped_files = get_files(cropped_path, extensions=['.jpg'], recurse=True)
    df = convert_cropped_files_todf(cropped_files)
    metadf = read_metadata(video_path/f'dfdc_train_part_{part_no}/metadata.json')
    metadf['video_fname'] = metadf.fname.apply(lambda o: Path(o).stem)
    metadf['label'] = metadf['label'].map({"REAL":0, "FAKE":1})
    merged_df = df.merge(metadf[['video_fname', 'label']], on="video_fname", how="left")
    assert not sum(merged_df.isna().any())
    return merged_df

# Cell
class SingleFrameDataset(Dataset):
    def __init__(self, flat_df):
        self.flat_df = flat_df

    def __getitem__(self, i):
        d1 = dict(self.flat_df.iloc[i])
        img = open_image(d1['frame_fname']).resize(299).data
        d2 = {"image":  img}
        return {**d1, **d2}

    def __len__(self):
        return len(self.flat_df)

# Cell
class SingleFrameSampler(Sampler):
    def __init__(self, df, flat_df):
        self.df, self.flat_df = df, flat_df

    def __iter__(self):
        # sample FAKE and REAL videos equally for each class
        class_counts = Counter(self.df['label'])
        minority_num_samples = class_counts[0]
        minority_fnames = self.df[self.df['label'] == 0]['video_fname'].values
        majority_fnames = self.df[self.df['label'] == 1].sample(minority_num_samples)['video_fname'].values
        minority_fnames, majority_fnames
        sampled_fnames = np.concatenate([minority_fnames, majority_fnames])
        sampled_df = self.df[self.df['video_fname'].isin(sampled_fnames)]

        # sample single frame for each sampled video
        res = []
        for _, row in sampled_df.iterrows():
            video_fname = row['video_fname']
            frame_fname = np.random.choice(row['frame_fnames'])
            res.append({'video_fname':video_fname, 'frame_fname':frame_fname})
        sampled_flat_df = pd.DataFrame(res)
        sampled_flat_df['sample_this'] = 1
        merged_flat_df = self.flat_df.merge(sampled_flat_df,on=['video_fname', 'frame_fname'],how='outer')

        # iterator for the epoch
        return iter(np.random.permutation(list(merged_flat_df[~merged_flat_df.sample_this.isna()].index)))

# Cell
class SingleFrameValidationDataset(Dataset):
    def __init__(self, df):
        self.df = df

    def __getitem__(self, i):
        d1 = dict(self.df.iloc[i])
        img = torch.stack([open_image(o).resize(299).data for o in d1['frame_fnames']])
        d2 = {"image":  img}
        return {**d1, **d2}

    def __len__(self):
        return len(self.df)