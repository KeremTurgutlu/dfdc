# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/12_generate_face_detections.ipynb (unless otherwise specified).

__all__ = ['generate_face_detections']

# Cell
from fastscript import call_parse, Param
from fastai.imports import *
from tqdm import tqdm

# Cell
from ..core.video_core import *
from .bbox_utils import *
from .retinaface import *
from fastai.data_block import get_files

# Cell
def generate_face_detections(video_files_txt:Param("csv or txt with list of video paths", type=str),
                            freq:Param("Sample frequency for reading videos", type=int),
                            modelname:Param("Detection model backbone", type=str),
                            confidence_threshold:Param("confidence_threshold", type=float) = 0.5,
                            top_k:Param("top_k before nms", type=int) = 5,
                            nms_threshold:Param("nms_threshold", type=float) = 0.5,
                            keep_top_k:Param("keep_top_k after nms", type=int) = 5):

    # retinaface model arguments
    model_args = dict(confidence_threshold = confidence_threshold,
                      top_k = top_k,
                      nms_threshold = nms_threshold,
                      keep_top_k = keep_top_k)

    # load model
    model, cfg = get_model(modelname)

    # get all video files under dir
    video_files = list(map(lambda o: Path(o), list(pd.read_csv(video_files_txt).iloc[:,0].values)))

    # get face detections
    res = []
    for fname in tqdm(video_files):
        # get face detections per video
        sz = cfg['image_size']
        t, t_raw, (H,W), len_video = get_decord_video_batch_cpu(fname, freq, sz, retinaface_stats)
        bboxes, landmarks = predict(model, t, sz, cfg, **model_args)
        orig_bboxes = bboxes_to_original_scale(bboxes, H, W, sz)
        orig_landmarks = landmarks_to_original_scale(landmarks, H, W, sz)
        orig_bboxes = [o.tolist() for o in orig_bboxes]
        orig_landmarks = [o.tolist() for o in orig_landmarks]

        # generate structured output
        video_res = {}
        video_res["fname"] = fname.name
        video_res["size"] = (H, W)
        video_res["face_detections"] = [{"frame_no":frame_no, "detections":detections, "landmarks":landmarks}
                                            for frame_no, detections, landmarks in
                                            zip(range(0, len_video, freq), orig_bboxes, orig_landmarks)]
        video_res["n_frames"] = t.shape[0]
        video_res["sample_freq"] = freq
        video_res["len_video"] = len_video
        res.append(video_res)

    # generate dataframe
    df = pd.DataFrame(res)
    return df